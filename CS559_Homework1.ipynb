{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Robert Miller"
      ],
      "metadata": {
        "id": "kN9qGQnLY8PL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I pledge my Honor that I Have abided by the Stevens Honor System"
      ],
      "metadata": {
        "id": "lFVpy89BZMx5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Linear Regression Modification"
      ],
      "metadata": {
        "id": "8xUB439JY9a1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#a) Import pandas and read df\n",
        "#Start by imporating pandas and the data\n",
        "import pandas as pd\n",
        "df = pd.read_csv('Realestate.csv')"
      ],
      "metadata": {
        "id": "ZcJQNyiIZQ15"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Drop numbers? It will get in the way\n",
        "df = df.drop(columns = \"No\")"
      ],
      "metadata": {
        "id": "KR79Xkp_gfWo"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#b) Standardize the\n",
        "#.mean() returns the average for the cols, and .std will return the standard deviation\n",
        "for col in df.columns:\n",
        "  df[col] = (df[col] - df[col].mean()) / df[col].std()\n",
        "#Store Y in an array\n",
        "y = df['Y house price of unit area']\n",
        "#then drop it from the features in dataframe\n",
        "df = df.drop(columns = \"Y house price of unit area\")"
      ],
      "metadata": {
        "id": "MMXX9mmBaVHI"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#c)\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "import numpy as np\n",
        "model = LinearRegression()\n",
        "model.fit(df, y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "PwfhrJMthBam",
        "outputId": "d4f6b835-700e-413d-c1c3-b6827ad26f2e"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearRegression()"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#predict values\n",
        "y_hat = model.predict(df)\n",
        "# print(y_hat)\n",
        "#report the root mean square error value (RMSE)\n",
        "sklearnRMSE = np.sqrt(mean_squared_error(y, y_hat))\n",
        "print(\"RMSE: \", sklearnRMSE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_mXsld6fl90v",
        "outputId": "44807afa-3fc5-42ef-e539-0c2eea03a56a"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE:  0.6454616841394373\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#d) Numpy Linear Regression\n",
        "#I copied and pasted this from the lecture's notebook code, as said in the homework document\n",
        "class Linear_regression():\n",
        "\n",
        "    def __init__(self, learning_rate, iterations):\n",
        "        self.learning_rate = learning_rate\n",
        "        self.iterations = iterations\n",
        "\n",
        "    # Model Training Function\n",
        "    def fit( self, X, Y):\n",
        "\n",
        "        # Number of training example, Number of features\n",
        "        self.m, self.n = X.shape\n",
        "\n",
        "        # Weight initialization\n",
        "\n",
        "        self.W = np.zeros( self.n)\n",
        "        self.b = 0\n",
        "        self.X = X\n",
        "        self.Y = Y\n",
        "\n",
        "        # Gradient Descent Learning\n",
        "        for i in range(self.iterations):\n",
        "            self.update_weights()\n",
        "        return self\n",
        "\n",
        "    # Function to update weights in Gradient Descent\n",
        "    def update_weights(self):\n",
        "        Y_pred = self.predict( self.X)\n",
        "\n",
        "        # Gradient calculations\n",
        "        dW = - (2 * (self.X.T).dot( self.Y - Y_pred)) / self.m\n",
        "        db = - 2 * np.sum( self.Y - Y_pred) / self.m\n",
        "\n",
        "        # Weight updates\n",
        "        self.W = self.W - self.learning_rate * dW\n",
        "        self.b = self.b - self.learning_rate * db\n",
        "\n",
        "        return self\n",
        "    # Hypthetical Function\n",
        "    def predict( self, X):\n",
        "\n",
        "        return X.dot( self.W) + self.b\n"
      ],
      "metadata": {
        "id": "JatH1Ro4mLmp"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = Linear_regression(learning_rate = 0.01, iterations = 5000)\n",
        "model2.fit(df, y)\n",
        "h_hat = model2.predict(df)\n",
        "print(\"Learning Rate = 0.001, Iteratinos  = 5000\")\n",
        "print(\"Mean Absolute Error: \", mean_absolute_error(y, h_hat))\n",
        "print(\"Mean Squared Error: \", mean_squared_error(y, h_hat))\n",
        "print(\"Root Mean Squared Error: \", np.sqrt(mean_squared_error(y, h_hat)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QaaQtfrwqeWE",
        "outputId": "27a1560e-0d0b-45a2-d291-d94c00e4733b"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Learning Rate = 0.001, Iteratinos  = 5000\n",
            "Mean Absolute Error:  0.45057549717256046\n",
            "Mean Squared Error:  0.41662078569211963\n",
            "Root Mean Squared Error:  0.645461684139438\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#e) Stochastic Gradient Descent in this version, so I made is Linear_regression2\n",
        "#I copied and pasted this from the lecture's notebook code, as said in the homework document\n",
        "class Linear_regression2():\n",
        "\n",
        "    def __init__(self, learning_rate, iterations):\n",
        "        self.learning_rate = learning_rate\n",
        "        self.iterations = iterations\n",
        "\n",
        "    # Model Training Function\n",
        "    def fit( self, X, Y):\n",
        "\n",
        "        # Number of training example, Number of features\n",
        "        self.m, self.n = X.shape\n",
        "\n",
        "        # Weight initialization\n",
        "\n",
        "        self.W = np.zeros( self.n)\n",
        "        self.b = 0\n",
        "        self.X = X\n",
        "        self.Y = Y\n",
        "\n",
        "        # Stochastic Gradient Descent Learning\n",
        "        for i in range(self.iterations):\n",
        "            self.update_weights()\n",
        "        return self\n",
        "\n",
        "    # Function to update weights in Stochastic Gradient Descent\n",
        "    def update_weights(self):\n",
        "\n",
        "        #Shuffle X and Y\n",
        "        shuffled_X = self.X.sample(frac = 1)\n",
        "        shuffled_Y = self.Y.sample(frac = 1)\n",
        "        for key, value in shuffled_X.iterrows():\n",
        "          Y_pred = self.predict(shuffled_X.loc[key]) #the key is shuffled with X so y is shuffled in line\n",
        "          # Stochastic Gradient calculations\n",
        "          dW = - (2 * (shuffled_X.loc[key].T) * ( shuffled_Y.loc[key] - Y_pred)) / self.m\n",
        "          db = - 2 * np.sum( self.Y - Y_pred) / self.m\n",
        "\n",
        "          # Weight updates\n",
        "          self.W = self.W - self.learning_rate * dW\n",
        "          self.b = self.b - self.learning_rate * db\n",
        "\n",
        "        return self\n",
        "    # Hypthetical Function\n",
        "    def predict( self, X):\n",
        "\n",
        "        return X.dot( self.W) + self.b\n"
      ],
      "metadata": {
        "id": "90T1yhcMFkMr"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model3 = Linear_regression2(learning_rate = 0.11, iterations = 50) #so few iterations since over 100 makes this take 5 mins on my computer\n",
        "model3.fit(df, y)\n",
        "h_hat = model3.predict(df)\n",
        "print(\"Learning Rate = 0.11, Iteratinos  = 50\")\n",
        "print(\"Mean Absolute Error: \", mean_absolute_error(y, h_hat))\n",
        "print(\"Mean Squared Error: \", mean_squared_error(y, h_hat))\n",
        "print(\"Root Mean Squared Error: \", np.sqrt(mean_squared_error(y, h_hat)))"
      ],
      "metadata": {
        "id": "HwU05JYkNDO-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a54bacf-fff4-40ec-b52a-4cb8ee5191ef"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Learning Rate = 0.11, Iteratinos  = 50\n",
            "Mean Absolute Error:  0.6393791684860177\n",
            "Mean Squared Error:  0.6339925408537331\n",
            "Root Mean Squared Error:  0.7962364855077498\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bayesian Theroem"
      ],
      "metadata": {
        "id": "GqZK0Tbvy4QC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('data.csv')\n",
        "# print(df)"
      ],
      "metadata": {
        "id": "iWMBgM6ezAgz"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#b) calculate a probability of x and y\n",
        "x_zero = 0\n",
        "y_zero = 0\n",
        "for key, row in df.iterrows():\n",
        "  if row.X == 0 :\n",
        "    x_zero += 1\n",
        "  if row.Y == 0 :\n",
        "    y_zero += 1\n",
        "#df.shape[0] is the row count of the csv\n",
        "#p(x=0)\n",
        "px_zero =  x_zero / df.shape[0]\n",
        "print(\"p(x = 0) = \",px_zero)\n",
        "#p(x=1)\n",
        "px_one = 1 - px_zero\n",
        "print(\"p(x = 1) = \", px_one)\n",
        "#p(y=0)\n",
        "py_zero = y_zero / df.shape[0]\n",
        "print(\"p(y = 0) = \", py_zero)\n",
        "#p(y=1)\n",
        "py_one = 1 - py_zero\n",
        "print(\"p(y = 1) = \", py_one)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dIE3v_H4zom1",
        "outputId": "7af6b032-04dd-46ed-ec1a-95d3fd1b32cd"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "p(x = 0) =  0.5555555555555556\n",
            "p(x = 1) =  0.4444444444444444\n",
            "p(y = 0) =  0.5252525252525253\n",
            "p(y = 1) =  0.4747474747474747\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#c) Calculate the liklihoods of, P(A | B) = P(A && B) / P(B)\n",
        "# p(x=0 | y = 0)\n",
        "xzyz = df[(df['Y'] == 0) & (df['X'] == 0)].shape[0] / (df['Y'] == 0).sum()\n",
        "print(\"p(x=0 | y = 0) = \", xzyz)\n",
        "# # p(x = 1| y = 0)\n",
        "xoyz = df[(df['Y'] == 0) & (df['X'] == 1)].shape[0] / (df['Y'] == 0).sum()\n",
        "print(\"p(x=1 | y = 0) = \", xoyz)\n",
        "# # p(x=0 | y = 1)\n",
        "xzyo = df[(df['Y'] == 1) & (df['X'] == 0)].shape[0] / (df['Y'] == 1).sum()\n",
        "print(\"p(x=0 | y = 1) = \", xzyo)\n",
        "# # p(x = 1| y = 1)\n",
        "xoyo = df[(df['Y'] == 1) & (df['X'] == 1)].shape[0] / (df['Y'] == 1).sum()\n",
        "print(\"p(x=1 | y = 1) = \", xoyo)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y30kEJdk3sjg",
        "outputId": "9f66ab50-c753-4f4c-ea98-df1c6be42735"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "p(x=0 | y = 0) =  0.5769230769230769\n",
            "p(x=1 | y = 0) =  0.4230769230769231\n",
            "p(x=0 | y = 1) =  0.5319148936170213\n",
            "p(x=1 | y = 1) =  0.46808510638297873\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#d) Calculate the posterior probabilies of, P(A | B) = P(B|A) * P(A) / P(B)\n",
        "# p(y = 0 | x = 0)\n",
        "yzxz = (xzyz * py_zero) / px_zero\n",
        "print(\"p(y = 0 | x = 0) = \", yzxz)\n",
        "# p(y = 0 | x = 1)\n",
        "yzxo = (xoyz * py_zero) / px_one\n",
        "print(\"p(y = 0 | x = 1) = \", yzxo)\n",
        "# p(y = 1 | x = 0)\n",
        "yoxz = (xzyo * py_one) / px_zero\n",
        "print(\"p(y = 1 | x = 0) = \", yoxz)\n",
        "# p(y = 1 | x = 1)\n",
        "yoxo = (xoyo * py_one) / px_one\n",
        "print(\"p(y = 1 | x = 1) = \", yoxo)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CG8rQLr48yoX",
        "outputId": "5c807755-6fce-4af2-fa71-1368c3a4f05d"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "p(y = 0 | x = 0) =  0.5454545454545454\n",
            "p(y = 0 | x = 1) =  0.5000000000000001\n",
            "p(y = 1 | x = 0) =  0.4545454545454545\n",
            "p(y = 1 | x = 1) =  0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LDA"
      ],
      "metadata": {
        "id": "tDhP_Ett_Vj4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import datasets\n",
        "import numpy as np\n",
        "X, y = datasets.make_blobs(n_samples = 100, n_features = 4, centers = 2, cluster_std = 1.5, random_state = 123)\n",
        "y = np.array([-1 if i == 0 else 1 for i in y])"
      ],
      "metadata": {
        "id": "h57Pl5Uo_5-C"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split (X,y,test_size = 0.2, random_state = 42)"
      ],
      "metadata": {
        "id": "TEVm_0eVCLlb"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 1 - calculate the mean separation, and between class matrix (Sb)\n",
        "mean_vectors = []\n",
        "m2 = np.mean(X_train[y_train == -1], axis = 0)\n",
        "m1 = np.mean(X_train[y_train == 1], axis = 0)\n",
        "mean_vectors.append(m1)\n",
        "mean_vectors.append(m2)\n",
        "print(\"Mean Vectors: \", mean_vectors)\n",
        "mean_separation = m2 - m1\n",
        "print(\"Mean Separation: \", mean_separation)\n",
        "sB = np.outer(mean_separation , mean_separation.T)\n",
        "print(\"Sb = \", sB)"
      ],
      "metadata": {
        "id": "2ajKhglKCrzs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f134b90-c9f9-4966-9bce-bc40e9f145d8"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Vectors:  [array([ 3.86695443, -1.65152113,  9.54411923,  3.57230245]), array([ 4.13391297, -4.43739756, -5.17160943,  0.96271724])]\n",
            "Mean Separation:  [  0.26695854  -2.78587643 -14.71572866  -2.60958521]\n",
            "Sb =  [[ 7.12668604e-02 -7.43713495e-01 -3.92848939e+00 -6.96651049e-01]\n",
            " [-7.43713495e-01  7.76110748e+00  4.09962016e+01  7.26998193e+00]\n",
            " [-3.92848939e+00  4.09962016e+01  2.16552670e+02  3.84019479e+01]\n",
            " [-6.96651049e-01  7.26998193e+00  3.84019479e+01  6.80993497e+00]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 2 - compute Sw (within class scatter)\n",
        "class_none = X_train[y_train == -1]\n",
        "class_one = X_train[y_train == 1]\n",
        "\n",
        "sW1 = np.dot((class_none - m1).T, (class_none - m1))\n",
        "sW2 = np.dot((class_one - m2).T, (class_one - m2))\n",
        "print(\"Sw1 = \", sW1)\n",
        "print(\"Sw2 = \", sW2)\n",
        "SW = sW1 + sW2\n",
        "print(\"SW = \", SW)\n",
        "SW_inverse = np.linalg.inv(SW)\n",
        "print(\"SW^-1 = \", SW_inverse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3iqLy_WpHIer",
        "outputId": "4bf97319-c244-4f59-d1ac-406906f23530"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sw1 =  [[ 109.63726451  -20.66474812 -177.17805303  -14.6574948 ]\n",
            " [ -20.66474812  445.13019314 1716.11056492  315.81648874]\n",
            " [-177.17805303 1716.11056492 9181.26536024 1628.5933453 ]\n",
            " [ -14.6574948   315.81648874 1628.5933453   387.54375197]]\n",
            "Sw2 =  [[  85.17740249  -32.30373058 -153.52154243  -32.89242658]\n",
            " [ -32.30373058  379.78264102 1561.57969395  271.64703011]\n",
            " [-153.52154243 1561.57969395 8297.56706021 1446.10822877]\n",
            " [ -32.89242658  271.64703011 1446.10822877  304.98072565]]\n",
            "SW =  [[  194.814667     -52.9684787   -330.69959545   -47.54992138]\n",
            " [  -52.9684787    824.91283416  3277.69025887   587.46351884]\n",
            " [ -330.69959545  3277.69025887 17478.83242044  3074.70157407]\n",
            " [  -47.54992138   587.46351884  3074.70157407   692.52447763]]\n",
            "SW^-1 =  [[ 0.00533373 -0.00021089  0.00020352 -0.00035849]\n",
            " [-0.00021089  0.00478188 -0.00084293 -0.00032845]\n",
            " [ 0.00020352 -0.00084293  0.00041504 -0.0011137 ]\n",
            " [-0.00035849 -0.00032845 -0.0011137   0.00664266]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 3, solution can be found by Sw-1 * Sb\n",
        "SW_inverse_SB = np.matmul(SW_inverse ,sB)\n",
        "print(\"Inverse: \", SW_inverse_SB)\n",
        "#calculate the eigenvalues and eigenvectors\n",
        "eigenvalues, eigenvectors = np.linalg.eig(SW_inverse_SB)\n",
        "eigenvalues = eigenvalues.real\n",
        "eigenvectors =  eigenvectors.real\n",
        "print(\"Eigenvalues: \", eigenvalues)\n",
        "print(\"Eigenvectors: \", eigenvectors)\n",
        "#Transform X_Train to project the eigenvetors\n",
        "# X_transform = np.dot(X_train, eigenvectors)\n",
        "#The best Eigenvalue for binary classification is 1.239569e-02, this one is the largest\n",
        "#and is therefore better to use to distinguish between classes as it would a larger\n",
        "#Separation between the classes\n",
        "#The corresponding eigenvector, [-0.05874635, -0.14249608, -097591602, -0.15437502]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CYq-ow5pX66b",
        "outputId": "70b0e89c-0640-47e4-8d21-6b149ee0b8fe"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inverse:  [[-1.28355038e-05  1.33946372e-04  7.07539806e-04  1.25470200e-04]\n",
            " [-3.11340008e-05  3.24902436e-04  1.71621973e-03  3.04342498e-04]\n",
            " [-2.13228118e-04  2.22516648e-03  1.17539119e-02  2.08435718e-03]\n",
            " [-3.37294335e-05  3.51987372e-04  1.85928945e-03  3.29713490e-04]]\n",
            "Eigenvalues:  [-1.73472348e-18  1.23956923e-02 -1.08035799e-17 -2.33223047e-18]\n",
            "Eigenvectors:  [[-0.99984555 -0.05874635 -0.01853645 -0.56283988]\n",
            " [-0.00250869 -0.14249608 -0.33888742  0.75761542]\n",
            " [-0.01718134 -0.97591602 -0.10200419 -0.09764458]\n",
            " [-0.00271783 -0.15437502  0.93509725 -0.31574624]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "#Step 4, project chosen eigenvector onto the test data and predict\n",
        "X_fit = np.dot(X_train, eigenvectors[:,1])\n",
        "y_hat = np.where(X_fit <= 0, 1, -1) #this sets the predictions based on if the value in X_Fit is >= 0\n",
        "accuracy = accuracy_score(y_train, y_hat)\n",
        "\n",
        "print(\"Accuracy Score: \", accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ffJVSwZhcqJl",
        "outputId": "62506c6c-6c7f-4740-b2d4-ec9ebd3bab6c"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy Score:  1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "#Step 5, project chosen eigenvector onto the train data and predict\n",
        "X_fit = np.dot(X_test, eigenvectors[:,1])\n",
        "y_hat = np.where(X_fit <= 0, 1, -1) #this sets the predictions based on if the value in X_Fit is >= 0\n",
        "accuracy = accuracy_score(y_test, y_hat)\n",
        "\n",
        "print(\"Accuracy Score: \", accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ngKhBNt_gRQu",
        "outputId": "7b96fcd7-1e0f-4aa1-b59e-5c4275904c16"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy Score:  1.0\n"
          ]
        }
      ]
    }
  ]
}